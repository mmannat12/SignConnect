

---

# ğŸ¤ SignConnect - Real-Time Indian Sign Language to Text & Speech Converter

**SignConnect** is a real-time deep learning application that bridges the gap between the Deaf and Hearing communities. Using gesture recognition, it translates **Indian Sign Language (ISL)** into **English text** and **speech**, enabling smoother and more inclusive communication.

---

## ğŸ› ï¸ Tech Stack

* **Python** ğŸ
* **OpenCV** ğŸ¥ â€“ Real-time video processing
* **MediaPipe** âœ‹ â€“ Hand landmark detection
* **TensorFlow / Keras** ğŸ§  â€“ CNN-based gesture classification
* **pyttsx3** ğŸ”Š â€“ Text-to-speech conversion
* **NumPy, PIL** ğŸ“Š â€“ Image processing and data handling

---

## âœ¨ Features

* ğŸ”¤ Converts **Indian Sign Language gestures** to English text
* ğŸ”Š Speaks the translated text using **text-to-speech**
* ğŸ¥ Real-time gesture recognition from webcam feed
* ğŸ’¡ User-friendly GUI for smooth interaction
* ğŸ§  Trained CNN model on a custom gesture dataset
* ğŸ§ª Modular code structure for easy experimentation and extension

---

## ğŸ” How It Works

1. **Hand Gesture Detection**: Uses **MediaPipe** to detect and track hand landmarks from the webcam.
2. **Preprocessing**: Captures and processes the hand region (cropped + resized).
3. **Gesture Prediction**: A trained **CNN model** predicts the class/label of the gesture.
4. **Output**: Displays the translated **text** and optionally converts it to **speech** using `gTTS`.

---

## ğŸ—‚ï¸ Project Structure

```
SignConnect/
â”‚
â”œâ”€â”€ dataset/                 # Preprocessed gesture images for training
â”œâ”€â”€ model/                   # Trained CNN model (model.h5)
â”œâ”€â”€ HandTrackingModule.py    # MediaPipe hand detection module
â”œâ”€â”€ main.py                  # Main application script with GUI
â”œâ”€â”€ model_train.py           # Training script for CNN model
â”œâ”€â”€ utils.py                 # Utility functions
â”œâ”€â”€ requirements.txt         # Required Python packages
â””â”€â”€ README.md                # Project documentation
```

---

## ğŸ“¦ Requirements

Install all dependencies using:

```bash
pip install -r requirements.txt
```

Main Libraries:

* `opencv-python`
* `mediapipe`
* `tensorflow`
* `gtts`
* `tkinter` (built-in with Python on most systems)
* `numpy`
* `Pillow`

---

## ğŸ’¡ Use Cases

* ğŸ§â€â™‚ï¸ **Assistive Technology** for the Deaf community
* ğŸ« **Educational Tool** for learning ISL and sign language recognition
* ğŸ¥ **Healthcare Communication** with deaf/mute patients
* ğŸ“± Future integration with **mobile apps** or **web platforms**
* ğŸ§ª Research in Human-Computer Interaction (HCI) and accessibility

---

## ğŸš€ Future Improvements

* ğŸ¤– **LSTM integration** for continuous sentence-level predictions
* ğŸŒ Deploy as a **web application** or **mobile app**
* ğŸŒ Support for **multiple sign languages** (e.g., ASL, BSL)
* ğŸ§  Improve accuracy with **larger datasets** and **Transfer Learning**
* ğŸ¤ Add **speech-to-sign** mode for two-way interaction
* ğŸ§© Gesture correction and **auto-suggestion** for unclear signs

---


